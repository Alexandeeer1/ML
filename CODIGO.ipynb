{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del dataset\n",
    "extracted_dir = r\"C:\\Users\\alexa\\OneDrive\\Desktop\\DataSetSignos\"\n",
    "classes = os.listdir(extracted_dir)\n",
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar imágenes y etiquetas\n",
    "for i, sign_class in enumerate(classes):\n",
    "    class_dir = os.path.join(extracted_dir, sign_class)\n",
    "    if os.path.isdir(class_dir):\n",
    "        for image_name in os.listdir(class_dir):\n",
    "            image_path = os.path.join(class_dir, image_name)\n",
    "            if os.path.isfile(image_path):\n",
    "                image = cv2.imread(image_path)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                image = cv2.resize(image, (32, 32))\n",
    "                images.append(image)\n",
    "                labels.append(i)\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Expande las dimensiones de los datos de entrada\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "# Normalización de los datos\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar aumento de datos\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(classes), activation='softmax'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo con aumento de datos\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=32), \n",
    "                    steps_per_epoch=len(X_train) // 32, \n",
    "                    epochs=30, \n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluación del modelo en el conjunto de prueba\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Precisión en el conjunto de prueba:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de una imagen del dataset\n",
    "pic = Image.open(r\"C:\\Users\\alexa\\OneDrive\\Desktop\\DataSetSignos\\L\\IMG_0966.JPG\")\n",
    "pic = pic.convert(\"L\")\n",
    "pic = pic.resize((32, 32))\n",
    "pic_arr = np.array(pic) / 255.0\n",
    "pic_arr = np.expand_dims(pic_arr, axis=0)\n",
    "prediction = model.predict(pic_arr)\n",
    "predicted_class = np.argmax(prediction)\n",
    "\n",
    "print(\"Predicción:\", predicted_class)\n",
    "\n",
    "predicted_class_name = classes[predicted_class]\n",
    "print(\"Clase predicha:\", predicted_class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de una imagen dentro del dataset\n",
    "k = 2\n",
    "pic = Image.open(\"C:\\\\Users\\\\alexa\\\\OneDrive\\\\Desktop\\\\DataSetSignos\\\\L\\\\IMG_0966.JPG\")\n",
    "pix = np.array(pic)\n",
    "print(type(pic))\n",
    "\n",
    "plt.imshow(pic.resize((32 * k, 32 * k)))\n",
    "plt.show()\n",
    "\n",
    "# Gráfico para la precisión\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()\n",
    "\n",
    "# Gráfico para la pérdida\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
