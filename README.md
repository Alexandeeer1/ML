# ML
WorkStation of Machine Learning Proyect


El lenguaje de señas es una forma de comunicación que utilizan las personas con discapacidad auditiva o que no pueden hablar. El lenguaje de señas consiste en gestos con las manos, el cuerpo y la cara que representan palabras, conceptos o emociones. El lenguaje de señas varía según el país o la región donde se habla. Por ejemplo, la Lengua de Señas Argentina (LSA) es diferente de la Lengua de Señas Española (LSE) o de la American Sign Language (ASL).


El deep learning y el machine learning son técnicas de inteligencia artificial que permiten a las computadoras aprender de los datos y realizar tareas complejas. El deep learning es un tipo de machine learning que utiliza redes neuronales artificiales con muchas capas para procesar información. El machine learning es un campo más amplio que incluye otros métodos como el aprendizaje supervisado, el aprendizaje no supervisado y el aprendizaje por refuerzo. Un ejemplo de deep learning es el reconocimiento facial, que identifica a las personas por sus rasgos faciales. Un ejemplo de machine learning es el filtro de spam, que clasifica los correos electrónicos como deseados o no deseados.


El lenguaje de señas con deep learning y machine learning es una aplicación que busca facilitar la comunicación entre las personas que usan el lenguaje de señas y las que no. Esta aplicación puede consistir en un sistema de reconocimiento de gestos que traduce el lenguaje de señas a texto o voz, o en un sistema de generación de gestos que traduce el texto o la voz a lenguaje de señas. Estos sistemas pueden usar cámaras, sensores o guantes para capturar los movimientos de las manos y el rostro, y redes neuronales para clasificarlos o generarlos. Un ejemplo de esta aplicación es el proyecto SignAll, que usa una cámara 3D y un guante sensorizado para reconocer el lenguaje de señas americano y traducirlo a inglés.